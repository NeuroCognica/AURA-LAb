# Target Funders and Research Organizations

**Note:** Contact information should be researched at time of outreach. This list provides organization names, suggested contact roles, and positioning angles.

---

## AI Safety / Governance Funders

### 1. Open Philanthropy
**Contact:** Program Officer, AI Safety or Technical AI Safety
**Angle:** "Behavioral governance for deployed agentic systems—complementary to alignment research, focused on near-term operational controls."
**Notes:** Large grants possible. Prefers detailed proposals. Long decision cycles.

### 2. Survival and Flourishing Fund (SFF)
**Contact:** Grant Manager or apply through recommendations
**Angle:** "Tractable governance mechanisms for AI agents that exist today, not hypothetical future systems."
**Notes:** Regranting fund. Smaller grants, faster cycles. Recommendation-based.

### 3. Long-Term Future Fund (EA Funds)
**Contact:** Fund Manager
**Angle:** "Infrastructure for human oversight of autonomous systems—trajectory-aware controls, not just permissions."
**Notes:** Accepts public applications. Quarterly cycles.

### 4. Lightspeed Grants (a][ ventures)
**Contact:** Through application portal
**Angle:** "Reference implementation of execution governance for AI agents. Code exists. Seeking evaluation funding."
**Notes:** Fast decisions. Smaller amounts. Proof of work matters.

### 5. Schmidt Sciences / Schmidt Futures
**Contact:** Program Director, AI or Technology
**Angle:** "Practical governance framework for agentic AI deployments—bridging security and AI safety."
**Notes:** Larger grants. Longer cycles. Institutional credibility helps.

---

## Research Organizations (Collaboration / Affiliation)

### 6. Center for Human-Compatible AI (CHAI), UC Berkeley
**Contact:** Research Director or Principal Investigator in relevant area
**Angle:** "Complementary to alignment—EGD governs behavior trajectories, not objectives. Interested in research collaboration or feedback."
**Notes:** Academic. May offer visiting researcher positions. Publication-oriented.

### 7. Anthropic (External Research)
**Contact:** Research Partnerships or External Research team
**Angle:** "Operational governance for deployed Claude-class systems. Framework for graduated intervention and audit."
**Notes:** May fund external research. Interested in practical deployment safety.

### 8. Center for AI Safety (CAIS)
**Contact:** Research Director
**Angle:** "Governance mechanisms for the near-term agency gap—complements longer-term safety research."
**Notes:** Grants and fellowships. Focus on existential risk but interested in operational safety.

### 9. Partnership on AI
**Contact:** Research Lead or relevant working group chair
**Angle:** "Industry-applicable governance framework. Interested in contributing to standards or best practices."
**Notes:** Multi-stakeholder. May offer platform rather than funding. Good for visibility.

### 10. Machine Intelligence Research Institute (MIRI)
**Contact:** Research team or Executive Director
**Angle:** "EGD explicitly acknowledges it doesn't scale to superintelligence—focused on current systems. Interested in feedback on limitations framing."
**Notes:** Theoretical focus. May not be funding match but could provide review/feedback.

---

## Outreach Priority

| Priority | Organization | Rationale |
|----------|--------------|-----------|
| 1 | Lightspeed Grants | Fast, code-positive, small amounts to start |
| 2 | Long-Term Future Fund | Public applications, quarterly |
| 3 | Open Philanthropy | Larger grants, longer cycle |
| 4 | Anthropic | Direct relevance to deployed agents |
| 5 | CHAI | Academic credibility, collaboration |

---

## Research Before Contact

For each target, before reaching out:
1. Check current funding priorities / open calls
2. Identify specific program or person (not generic contact)
3. Review recent grants / publications for framing alignment
4. Tailor angle to their stated interests

---

## Template Customization

Use LETTER_TO_FUNDER.md as base. Customize:
- Recipient name/title
- Angle sentence (from above)
- Specific ask (call vs. grant application vs. feedback)
- Any shared context (mutual contacts, relevant publications they've funded)
